{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l6b8OzarSOeT",
    "outputId": "5078046a-9245-40a7-89cf-39415ef5503d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting netron\n",
      "  Downloading netron-6.7.7-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: netron\n",
      "Successfully installed netron-6.7.7\n"
     ]
    }
   ],
   "source": [
    "pip install netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FCuJKASO5tl9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "from torchviz import make_dot\n",
    "import netron\n",
    "from modeci_mdf.interfaces.pytorch import pytorch_to_mdf\n",
    "import torch\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1UYVv-epXm1O",
    "outputId": "e73b6d98-aa7f-49be-e050-c64f4d5a340e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = models.resnet18()\n",
    "model1.load_state_dict(torch.load('/content/resnet18.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJpyGg2_BRmS",
    "outputId": "d6346919-d0d9-4470-ad0e-fd9b882c92eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated the graph in PyTorch, output: tensor([[-2.8774e-02, -5.2932e-03, -3.6097e-02,  6.8579e-03, -3.4067e-03,\n",
      "         -3.0889e-02,  2.4735e-02,  4.2477e-02,  2.6443e-03,  2.1936e-02,\n",
      "         -3.2019e-02,  3.1720e-02, -4.2142e-02, -2.9292e-02,  1.8174e-02,\n",
      "         -1.4973e-02,  2.7067e-02, -9.0325e-03,  2.1031e-02, -9.1640e-03,\n",
      "         -6.0370e-03, -1.6253e-02, -4.0052e-02,  3.8943e-02,  3.0394e-02,\n",
      "         -1.6035e-02,  3.3327e-02,  1.1011e-02,  2.5651e-02,  6.3637e-03,\n",
      "         -4.0436e-02, -3.2286e-02, -5.7262e-03, -3.6450e-02, -3.5967e-02,\n",
      "         -2.9956e-02, -3.4702e-04,  1.7811e-02,  5.9253e-03,  3.3936e-03,\n",
      "          1.7460e-02,  4.2890e-02,  3.0843e-02,  4.2885e-02,  1.4251e-02,\n",
      "         -3.3574e-02,  2.6518e-02, -4.1100e-02, -3.5351e-02,  4.1666e-02,\n",
      "          3.2555e-02,  1.9023e-03, -3.2874e-02,  5.3508e-03, -1.6104e-02,\n",
      "          2.0862e-02,  4.0813e-02, -8.4683e-03,  1.7769e-02, -1.7465e-02,\n",
      "         -1.0925e-04,  6.1013e-03, -2.1344e-03, -2.1584e-02,  7.4184e-05,\n",
      "          1.4014e-03,  3.5097e-02,  1.5691e-02,  4.1722e-02,  4.4071e-02,\n",
      "          3.2907e-02, -2.2229e-02, -1.0017e-02,  2.0119e-02, -5.4927e-03,\n",
      "          3.0640e-02, -4.3290e-02, -5.5264e-03,  2.3029e-03,  2.2253e-02,\n",
      "          1.9400e-02,  3.2911e-02,  2.5305e-02,  2.3462e-02, -2.6238e-02,\n",
      "          3.7040e-02, -9.8449e-03, -2.1243e-02,  2.0307e-02, -1.4152e-02,\n",
      "         -2.7473e-02,  1.3462e-02,  1.7207e-02, -2.7928e-02,  2.7839e-02,\n",
      "         -4.3572e-02,  1.9013e-02,  2.6682e-02, -2.3957e-03,  3.9183e-02,\n",
      "          3.4427e-03, -1.4153e-02, -1.4710e-02,  3.5402e-02, -4.3382e-02,\n",
      "          3.0511e-02, -2.8732e-02,  2.4007e-02,  1.6410e-03,  2.5739e-02,\n",
      "         -7.0160e-03, -4.1413e-02, -3.8526e-02,  2.7180e-02,  4.3351e-02,\n",
      "          1.6644e-03, -4.0774e-02, -5.0119e-04, -1.8646e-02,  6.2270e-03,\n",
      "         -1.1224e-02, -3.0415e-02,  1.3348e-02, -3.1207e-02,  1.9975e-02,\n",
      "          4.0852e-02, -1.9508e-02,  1.7505e-02,  3.8582e-02, -3.6663e-02,\n",
      "         -1.5971e-02,  7.7736e-03,  3.9053e-03, -4.0782e-02,  1.5348e-02,\n",
      "         -7.7704e-03,  3.5343e-03,  3.9921e-02, -3.2603e-02, -1.6340e-02,\n",
      "         -9.4065e-03, -3.2074e-03,  1.7489e-03, -3.3376e-02,  1.6805e-02,\n",
      "         -3.9762e-02, -2.7101e-02, -3.7300e-02,  7.5016e-03, -2.4794e-02,\n",
      "          2.8284e-02,  1.5069e-02, -1.6519e-02,  1.6860e-02, -1.8443e-02,\n",
      "          2.3666e-02,  2.0870e-03,  2.7580e-02, -1.9525e-02,  1.5766e-02,\n",
      "         -4.7620e-03,  3.8811e-02, -3.4158e-02,  2.4692e-02, -2.4172e-02,\n",
      "         -2.6276e-02,  3.0478e-02,  8.8228e-03, -4.2559e-02,  4.2011e-02,\n",
      "         -3.2955e-02, -2.8850e-02, -2.9802e-02,  3.9884e-02,  1.8521e-02,\n",
      "          4.2365e-02,  4.0082e-02, -2.7503e-02, -1.8758e-02, -3.4502e-02,\n",
      "         -1.7437e-02,  2.8622e-02,  2.5877e-03, -9.5440e-03,  3.2397e-02,\n",
      "         -3.3758e-02, -1.8523e-02, -3.6612e-02, -3.4236e-02,  9.8851e-03,\n",
      "          2.3888e-02,  6.6822e-03, -1.6884e-02, -2.2946e-03,  1.9429e-02,\n",
      "          3.3045e-02, -1.6539e-02, -2.3999e-02, -1.8343e-02,  1.1159e-02,\n",
      "         -1.9482e-02,  3.5138e-02,  3.4883e-02, -1.4809e-02,  3.4248e-02,\n",
      "         -1.7455e-02, -1.5541e-02, -9.6738e-04, -8.8892e-03,  2.0095e-02,\n",
      "          1.6997e-02,  7.2584e-03, -1.0470e-02,  1.5384e-02,  7.6301e-03,\n",
      "         -1.9236e-02,  1.5434e-03, -3.3364e-02,  3.6206e-02,  1.0503e-02,\n",
      "          4.3223e-02,  1.5818e-02, -2.6233e-02,  2.7702e-02,  1.4858e-02,\n",
      "         -4.7677e-04,  3.6056e-02, -5.7913e-03,  1.5746e-02, -3.3766e-02,\n",
      "          1.9888e-02,  2.2432e-02, -2.6980e-04, -4.0192e-03, -2.5255e-02,\n",
      "          3.8145e-02,  1.0456e-02,  1.7509e-02,  1.2025e-02, -4.1115e-02,\n",
      "          3.6013e-02, -2.7472e-02, -1.0301e-03, -8.1659e-03, -3.8864e-02,\n",
      "          2.2962e-02,  2.6122e-02,  2.0483e-02, -2.7810e-02, -2.4516e-02,\n",
      "          3.6724e-02, -4.1655e-02, -2.5873e-02, -2.0757e-02,  2.1302e-02,\n",
      "          3.3336e-02, -2.4108e-02, -4.0854e-02, -2.5974e-02,  3.9439e-02,\n",
      "         -4.0238e-03, -6.7582e-03, -6.1097e-03,  2.3039e-02, -2.0769e-03,\n",
      "         -3.1676e-02, -6.0762e-03,  1.9218e-02, -1.4264e-02, -1.4809e-02,\n",
      "         -1.5035e-02,  4.0088e-02,  1.8507e-02,  5.1582e-04, -2.9667e-02,\n",
      "          1.3229e-02,  3.4314e-02,  2.0800e-02, -2.1966e-02,  8.1737e-03,\n",
      "          3.5627e-02,  2.2174e-02, -1.2481e-02,  3.7194e-02, -2.1239e-02,\n",
      "         -1.8495e-02, -3.7526e-02,  2.0387e-04,  2.6759e-04, -1.2986e-02,\n",
      "          1.9380e-02,  8.4678e-03, -4.2337e-02,  3.1565e-02, -2.5843e-02,\n",
      "         -1.9610e-02,  2.1090e-02,  3.0413e-03,  4.0627e-02, -6.3463e-03,\n",
      "         -3.4946e-02, -2.2544e-02, -3.3964e-02,  3.2070e-02,  1.2136e-02,\n",
      "         -1.5949e-03, -1.4823e-02, -1.4319e-02, -3.0946e-02, -2.8148e-02,\n",
      "          6.4753e-03, -2.5201e-02,  3.6095e-02, -1.9025e-03, -3.2630e-02,\n",
      "          4.7641e-03, -9.7984e-03, -3.6366e-02, -2.6813e-02,  7.7914e-03,\n",
      "         -8.1737e-03,  4.0297e-02,  2.0002e-02,  4.8076e-03, -3.3267e-02,\n",
      "         -1.7900e-02, -2.1264e-02, -6.8532e-03,  1.1482e-02, -3.6975e-02,\n",
      "         -4.9176e-04,  3.3843e-02,  6.7274e-03, -1.0330e-02, -2.5692e-02,\n",
      "          1.0802e-02, -3.7180e-02,  2.7209e-02, -4.3028e-02,  2.0886e-02,\n",
      "          1.9017e-02,  3.3507e-02, -6.0164e-03,  3.8031e-02, -2.0901e-02,\n",
      "         -3.0082e-02, -1.2823e-02, -1.6906e-03, -2.8135e-02, -5.7956e-04,\n",
      "          6.1138e-04, -7.3421e-03, -1.2578e-02, -3.5069e-02,  3.1194e-02,\n",
      "         -3.4615e-02, -3.7867e-02, -3.1263e-02, -3.2901e-02, -4.5681e-03,\n",
      "          3.0683e-02, -2.2863e-02,  3.1641e-02, -2.8487e-02,  3.9133e-02,\n",
      "         -5.7890e-03, -3.7340e-02, -4.0284e-02, -3.0427e-02, -2.8738e-02,\n",
      "         -1.2057e-02,  9.4452e-03,  2.6429e-02, -2.3932e-02, -4.1927e-02,\n",
      "          9.7901e-04, -1.2409e-02, -1.4882e-02,  2.3630e-02,  4.8617e-04,\n",
      "         -3.7250e-03,  2.8181e-02,  1.6248e-04,  1.1950e-02,  7.8393e-06,\n",
      "         -2.9053e-02,  1.4154e-02, -3.3875e-02, -3.9793e-02, -2.0524e-02,\n",
      "          1.9820e-02, -2.9439e-02,  2.1021e-02, -2.5904e-02, -7.3488e-03,\n",
      "         -1.0469e-02,  3.7646e-02,  2.0063e-02,  3.1544e-02, -3.0181e-02,\n",
      "         -3.4082e-02,  3.5126e-02, -2.0622e-02, -4.1949e-02,  3.6379e-02,\n",
      "          2.2334e-02,  6.5800e-03, -2.8511e-03, -3.9679e-02,  3.8406e-02,\n",
      "          3.0862e-02, -4.3534e-02,  2.3548e-02,  1.4773e-02, -2.7507e-02,\n",
      "          2.9886e-03, -1.3239e-02,  3.6185e-02,  1.7344e-02,  3.3823e-02,\n",
      "         -3.0626e-02,  3.3724e-02,  2.1688e-02,  2.4634e-03, -3.4963e-02,\n",
      "          5.2404e-03, -6.2796e-03,  1.6808e-02, -1.1859e-02, -2.5326e-02,\n",
      "         -2.4656e-02, -1.0159e-02,  1.4127e-02, -2.0072e-02,  1.5875e-02,\n",
      "         -2.2267e-02,  4.4972e-03, -2.5910e-02,  3.6730e-02, -3.0718e-02,\n",
      "          3.9384e-02, -8.1446e-03,  7.6864e-03, -8.1211e-03,  3.8088e-03,\n",
      "         -1.3527e-02, -4.2070e-02, -1.7782e-03,  2.2734e-02, -2.9960e-02,\n",
      "         -6.3354e-03, -1.4621e-02, -1.9665e-02,  1.7500e-02,  1.0202e-02,\n",
      "          1.2314e-03,  1.0288e-02, -1.7254e-03,  4.3606e-02, -1.8888e-03,\n",
      "         -2.0456e-02,  3.8783e-02,  8.7612e-03, -3.3739e-02,  8.0411e-03,\n",
      "          1.8434e-02, -4.0449e-02,  2.1780e-02, -3.6897e-03, -2.2677e-03,\n",
      "         -3.9079e-02, -4.1437e-02, -1.8804e-02, -3.9157e-02,  1.9627e-03,\n",
      "         -2.2201e-02,  3.9509e-02, -1.5736e-02, -2.8486e-02, -3.3223e-02,\n",
      "         -3.7987e-02, -6.9588e-03,  4.1878e-02,  4.0674e-02, -2.3397e-02,\n",
      "          3.7335e-03, -1.0832e-02,  2.1231e-02,  3.5055e-02, -7.4744e-04,\n",
      "         -1.3511e-02, -7.1683e-03, -8.5854e-04, -4.1153e-02, -8.4611e-03,\n",
      "         -8.5523e-03, -1.0113e-02, -3.1766e-02,  5.0362e-03,  3.0324e-02,\n",
      "          1.2509e-02,  1.1776e-02,  1.8387e-02,  4.0242e-02, -1.2053e-02,\n",
      "         -1.6343e-02,  3.5267e-03,  6.0517e-03,  2.5972e-03, -6.4158e-03,\n",
      "         -2.1233e-02, -9.4094e-03, -5.8818e-03,  6.5967e-03,  1.5484e-02,\n",
      "         -8.9029e-03,  3.1422e-02, -3.3631e-03, -2.4150e-02,  2.4068e-02,\n",
      "          1.2739e-02, -2.3548e-02, -9.7946e-03,  1.2982e-02,  2.1736e-02,\n",
      "          3.2666e-02, -2.2151e-02,  5.4281e-03, -2.4690e-02, -3.3362e-03,\n",
      "         -3.6427e-02,  1.0539e-02,  3.2635e-02, -2.5182e-02,  3.1912e-02,\n",
      "          2.0361e-02, -3.4102e-02,  1.4763e-03,  3.3988e-02,  1.9049e-02,\n",
      "         -7.5774e-03,  1.3053e-02,  2.3522e-02, -3.1368e-03, -5.0454e-03,\n",
      "         -3.0939e-02, -4.1909e-02, -4.1435e-02,  1.9443e-02,  4.0300e-02,\n",
      "          1.8252e-02, -2.4423e-03,  1.8828e-03, -4.0883e-02,  1.2272e-02,\n",
      "          4.2192e-02, -2.9796e-02,  1.5056e-02,  2.0654e-02, -3.6255e-02,\n",
      "         -2.1609e-03, -2.1337e-02,  2.2029e-02, -7.9741e-03,  1.3414e-02,\n",
      "         -1.1891e-02,  2.2862e-02, -1.1918e-03,  3.2440e-02, -2.7300e-03,\n",
      "          1.6624e-02,  1.3110e-02,  2.8868e-02,  2.4549e-02, -1.2016e-02,\n",
      "         -4.1363e-02,  7.3645e-03, -9.6692e-03, -1.7481e-02,  2.8580e-02,\n",
      "          2.2398e-03, -3.9793e-02,  1.4390e-02,  3.6379e-02, -3.9718e-02,\n",
      "          8.9959e-03, -1.4390e-02,  1.4616e-02,  3.0801e-02, -3.1879e-02,\n",
      "          3.4422e-02, -3.4331e-02,  4.7736e-03,  2.4173e-02, -3.0498e-02,\n",
      "         -1.6320e-03, -1.0877e-02, -1.3390e-03,  1.6426e-03,  7.4703e-03,\n",
      "         -1.1963e-02, -2.1461e-02,  1.7801e-02,  2.4992e-02,  1.4606e-02,\n",
      "         -3.5485e-02, -2.6041e-02,  1.7905e-02, -1.0329e-03,  2.1899e-03,\n",
      "          1.1102e-02,  2.3891e-02,  1.3843e-02, -4.3076e-02,  8.0513e-03,\n",
      "          2.0649e-03,  6.1838e-03, -8.0504e-03,  1.9208e-04, -9.6453e-03,\n",
      "         -3.0391e-02, -3.7890e-02, -5.2457e-03, -2.0205e-02,  1.6429e-02,\n",
      "         -7.4405e-03, -1.5137e-02,  5.7210e-03, -2.3313e-02, -2.8533e-03,\n",
      "         -3.4916e-02,  1.4791e-02, -5.5480e-03, -3.2063e-02,  3.7686e-03,\n",
      "         -1.4248e-02,  1.1899e-02, -1.2267e-02, -3.9867e-02,  2.4034e-02,\n",
      "          4.0446e-02, -2.0782e-02,  3.5755e-02, -1.5250e-02,  1.2654e-02,\n",
      "          3.9862e-02,  7.1686e-03, -1.5890e-02, -1.2686e-03, -3.9420e-02,\n",
      "         -5.9990e-03,  1.5831e-02,  3.0940e-02, -1.4099e-02,  3.8914e-02,\n",
      "         -1.4247e-02,  2.8870e-02, -1.9637e-02, -1.1543e-03, -3.6368e-02,\n",
      "         -1.6871e-02,  1.1085e-02,  3.5780e-03, -2.7196e-02,  3.8539e-03,\n",
      "          1.8678e-02,  2.8342e-02, -1.0241e-02,  3.8899e-02, -1.3920e-02,\n",
      "          4.3727e-02,  8.8541e-03, -8.4287e-03,  4.1992e-02, -2.6398e-02,\n",
      "          3.1382e-02, -3.6254e-02,  8.5592e-03,  1.8890e-02,  1.3427e-02,\n",
      "         -4.2968e-02, -2.4942e-02, -1.6291e-02,  7.5711e-03, -1.8667e-02,\n",
      "         -2.2748e-02, -3.3471e-02,  1.1225e-03, -4.2346e-02,  2.9923e-02,\n",
      "          1.9514e-02,  3.3470e-02,  2.4263e-03,  3.5533e-02,  1.2952e-02,\n",
      "         -2.9875e-02,  4.7060e-03,  3.6901e-02, -2.8325e-02,  2.4613e-02,\n",
      "         -2.3497e-02,  1.0845e-02,  3.3718e-02, -8.9162e-03, -3.8722e-02,\n",
      "          1.6608e-02, -1.9785e-02, -3.3981e-02, -1.2217e-02,  1.3585e-02,\n",
      "         -2.2409e-02, -1.0429e-02, -2.0098e-02, -3.7226e-02, -1.9482e-02,\n",
      "          2.7272e-02, -6.1440e-03, -2.7826e-03, -4.0351e-02, -4.6048e-03,\n",
      "         -2.1342e-02, -8.4188e-03, -1.9527e-02, -3.5651e-03,  6.4147e-03,\n",
      "         -2.6429e-02,  1.2400e-02,  2.6426e-02, -3.9855e-02, -2.7424e-02,\n",
      "          3.0276e-02,  1.0183e-02,  2.2398e-02,  2.7894e-02,  5.0964e-03,\n",
      "         -4.2177e-02, -3.5388e-02,  7.6188e-03, -1.9653e-02, -2.3716e-02,\n",
      "         -3.1438e-02,  2.7833e-02, -2.8367e-02, -3.6472e-02,  1.7179e-02,\n",
      "         -2.4442e-03, -3.7017e-02, -9.6460e-03,  7.8963e-04, -7.0353e-03,\n",
      "          1.3806e-02, -4.1708e-02,  1.0317e-03, -1.9001e-02, -3.3621e-02,\n",
      "         -1.0237e-03,  2.1523e-02, -4.2572e-02, -2.8787e-03,  2.0250e-02,\n",
      "         -9.9569e-04, -4.1995e-02,  4.0822e-02,  3.5237e-02, -7.4308e-03,\n",
      "          3.0007e-02, -1.7366e-02, -3.8786e-02, -2.1858e-02, -3.7584e-02,\n",
      "          7.8793e-03,  1.4900e-02,  4.1736e-02,  4.4102e-02, -6.8997e-04,\n",
      "         -3.0476e-02,  1.8677e-02, -3.1585e-02,  6.3439e-03, -1.0842e-02,\n",
      "          3.2164e-02,  1.9157e-02, -7.4724e-03, -3.9813e-02, -8.0888e-03,\n",
      "          6.1201e-04, -1.3613e-02,  3.6236e-02, -2.8950e-02, -2.6680e-02,\n",
      "         -1.1843e-03, -5.4451e-03,  1.7477e-02,  2.0385e-02,  2.2345e-02,\n",
      "         -2.2048e-02,  1.7412e-02,  2.7216e-02,  3.0519e-02,  3.0584e-02,\n",
      "          3.6555e-02,  1.7594e-02, -1.3661e-02, -8.4800e-03, -1.5977e-02,\n",
      "         -1.6416e-02, -1.0465e-02,  1.6666e-02, -3.8364e-02,  1.3196e-02,\n",
      "         -1.0838e-02,  3.2661e-02, -4.3487e-02, -3.1009e-02, -3.4371e-02,\n",
      "          1.3398e-02, -1.3275e-02,  1.3144e-04, -4.5021e-03, -7.2725e-03,\n",
      "          2.2720e-02,  4.3442e-02, -1.3248e-02, -1.3719e-02,  1.2777e-02,\n",
      "          2.2924e-04, -1.6180e-02, -4.2915e-02, -4.1181e-02,  7.7730e-03,\n",
      "          2.8468e-02,  2.4191e-02,  1.0248e-02,  3.8663e-02,  1.4152e-02,\n",
      "          3.9762e-02,  4.4111e-02, -3.5768e-02, -3.1741e-02,  1.6419e-02,\n",
      "          4.2097e-02, -1.7632e-02, -5.0892e-03, -2.0635e-02, -3.9940e-03,\n",
      "         -3.9341e-02, -3.3635e-02, -1.7447e-02,  1.4012e-02,  2.4209e-02,\n",
      "         -8.2435e-03,  3.4329e-02,  1.6815e-02,  1.0013e-02,  1.6438e-02,\n",
      "          2.4219e-02,  6.9993e-03, -1.2638e-02,  3.6366e-02,  3.7696e-02,\n",
      "         -8.1701e-03, -1.0017e-02,  9.4208e-03, -2.9158e-02,  2.0790e-02,\n",
      "         -5.4533e-03, -2.8587e-02,  3.5546e-02, -3.5438e-02, -2.9858e-03,\n",
      "         -2.9489e-02, -1.1127e-02,  1.1066e-02, -3.6064e-02, -2.3031e-02,\n",
      "          2.3434e-02, -2.5948e-02,  2.1694e-02, -1.9871e-02, -4.1099e-02,\n",
      "         -2.0000e-02,  1.5862e-02,  3.1371e-02,  1.0532e-02, -1.8139e-02,\n",
      "         -2.9882e-03,  1.2036e-02, -4.1184e-02,  1.6969e-02, -3.6052e-02,\n",
      "          6.6076e-03,  6.5260e-03, -2.2977e-02,  3.6997e-02,  4.3116e-02,\n",
      "          2.8921e-02, -3.9388e-02, -3.3041e-03, -2.5312e-02,  1.5647e-02,\n",
      "          8.0638e-03,  8.3244e-03,  5.8370e-04,  3.0245e-02, -2.5753e-02,\n",
      "          6.2867e-03,  1.3579e-02,  1.3808e-02, -2.1316e-02,  3.1596e-03,\n",
      "          9.0790e-03,  2.7811e-02, -2.8030e-02, -1.0278e-02, -9.4863e-03,\n",
      "         -5.7509e-03, -3.8393e-02,  1.5895e-02,  1.4777e-02,  3.1428e-03,\n",
      "          3.8704e-02, -4.2183e-02, -3.6456e-02, -8.2870e-03,  4.1104e-03,\n",
      "         -7.4542e-03, -4.1862e-02, -3.6866e-02, -2.5117e-02,  9.4268e-03,\n",
      "          1.5882e-02,  2.8959e-02, -2.6472e-02,  8.4191e-03, -1.0198e-02,\n",
      "         -3.9546e-02,  3.9015e-02, -3.9504e-02,  3.5956e-02,  1.5155e-02,\n",
      "         -3.3398e-02,  4.2536e-02, -6.2120e-03, -2.9081e-02, -6.3965e-03,\n",
      "         -3.0264e-03,  4.3142e-02,  3.4349e-02, -9.2346e-03,  3.2187e-02,\n",
      "         -2.2243e-02, -9.7820e-03,  2.9307e-02, -2.9733e-02, -3.6457e-03,\n",
      "         -2.8140e-02,  9.0684e-03,  1.1466e-02,  8.4883e-03,  2.3680e-02,\n",
      "         -4.0780e-02, -2.7338e-02, -5.8808e-03, -1.7303e-02,  4.2337e-02,\n",
      "         -3.4731e-02, -3.3559e-02, -4.1294e-02,  3.3574e-02, -1.9583e-02,\n",
      "         -7.6633e-03, -1.8312e-02,  9.9963e-04, -2.2371e-02, -3.6203e-02,\n",
      "          3.5587e-03,  1.1729e-02, -4.0511e-02,  1.4608e-03, -3.0097e-02,\n",
      "         -5.7584e-03, -2.7413e-02, -2.0090e-03,  1.8616e-02, -3.2963e-02,\n",
      "          7.9210e-03,  3.8000e-02, -4.2512e-03, -3.4697e-02, -3.8036e-02,\n",
      "          1.0665e-02, -2.1426e-02,  8.0536e-03, -4.9273e-03, -2.9399e-02,\n",
      "          3.8976e-03, -1.2528e-02, -3.8286e-03,  3.2078e-02,  1.5108e-02]],\n",
      "       grad_fn=<AddmmBackward0>)(Tensor)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/modeci_mdf/interfaces/pytorch/importer.py:517: FutureWarning: 'torch.onnx.symbolic_helper._set_opset_version' is deprecated in version 1.13 and will be removed in version 1.14. Please remove its usage and avoid setting internal variables directly.\n",
      "  _set_opset_version(modeci_onnx_opset_version)\n",
      "/usr/local/lib/python3.9/dist-packages/modeci_mdf/interfaces/pytorch/importer.py:526: FutureWarning: 'torch.onnx.symbolic_helper._set_opset_version' is deprecated in version 1.13 and will be removed in version 1.14. Please remove its usage and avoid setting internal variables directly.\n",
      "  _set_opset_version(previous_opset_version)\n",
      "/usr/local/lib/python3.9/dist-packages/modeci_mdf/interfaces/pytorch/importer.py:168: FutureWarning: 'torch.onnx._patch_torch._node_getitem' is deprecated in version 1.13 and will be removed in version 1.14. Please Internally use '_node_get' in symbolic_helper instead..\n",
      "  {aname: convert_to_serializable(node[aname]) for aname in node.attributeNames()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Init graph: ResNetGraph\n",
      "Evaluating graph: ResNetGraph, root nodes: ['Conv_192'], with array format numpy\n",
      "Evaluated the graph in PyTorch, output: [[-0.0287744 ...  0.0151076]] (NP (1, 1000) float64)\n",
      "Passed all comparison tests!\n",
      "Exported to MDF and ONNX\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # changed import call\n",
    "    from modeci_mdf.execution_engine import EvaluableGraph\n",
    "\n",
    "    # Create some test inputs for the model\n",
    "    input_images = torch.zeros((1, 3, 224, 224), requires_grad=False)\n",
    "\n",
    "    # Seed the random number generator to get deterministic behavior for weight initialization\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    model = model1\n",
    "\n",
    "    model.eval()\n",
    "    # Run the model once to get some ground truth outpot (from PyTorch)\n",
    "    output = model(input_images)\n",
    "\n",
    "    from modelspec.utils import _val_info\n",
    "\n",
    "    print(\"Evaluated the graph in PyTorch, output: %s\" % (_val_info(output)))\n",
    "\n",
    "    # Convert to MDF\n",
    "    mdf_model, params_dict = pytorch_to_mdf(\n",
    "        model=model,\n",
    "        args=(input_images),\n",
    "        trace=True,\n",
    "    )\n",
    "\n",
    "    # Get the graph\n",
    "    mdf_graph = mdf_model.graphs[0]\n",
    "\n",
    "    # Add inputs to the parameters dict so we can feed this to the EvaluableGraph for initialization of graph input.\n",
    "    params_dict[\"input1\"] = input_images.numpy()\n",
    "\n",
    "    # Evaluate the model via the MDF scheduler\n",
    "    eg = EvaluableGraph(graph=mdf_graph, verbose=False)\n",
    "    eg.evaluate(initializer=params_dict)\n",
    "    output_mdf = eg.output_enodes[0].get_output()\n",
    "\n",
    "    print(\"Evaluated the graph in PyTorch, output: %s\" % (_val_info(output_mdf)))\n",
    "    # Make sure the results are the same between PyTorch and MDF\n",
    "    assert np.allclose(\n",
    "        output.detach().numpy(),\n",
    "        output_mdf,\n",
    "    )\n",
    "    print(\"Passed all comparison tests!\")\n",
    "\n",
    "    # Output the model to JSON\n",
    "    mdf_model.to_json_file(\"sample1_pytorch_to_mdf.json\")\n",
    "\n",
    "    import sys\n",
    "\n",
    "    # Exporting as onnx model\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        input_images,\n",
    "        \"sample1_pytorch_to_mdf.onnx\",\n",
    "        verbose=True,\n",
    "        input_names=[],\n",
    "        opset_version=9,\n",
    "    )\n",
    "    onnx_model = onnx.load(\"sample1_pytorch_to_mdf.onnx\")\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    sess = rt.InferenceSession(\"sample1_pytorch_to_mdf.onnx\")\n",
    "    res = sess.run(None, {sess.get_inputs()[0].name: input_images.numpy()})\n",
    "    print(\"Exported to MDF and ONNX\")\n",
    "\n",
    "    # export to mdf graph\n",
    "    if \"-graph\" in sys.argv:\n",
    "        mdf_model.to_graph_image(\n",
    "            engine=\"dot\",\n",
    "            output_format=\"png\",\n",
    "            view_on_render=False,\n",
    "            level=1,\n",
    "            filename_root=\"sample1_pytorch_to_mdf.1\",\n",
    "            only_warn_on_fail=True,  # Makes sure test of this doesn't fail on Windows on GitHub Actions\n",
    "            is_horizontal=True,\n",
    "            rankdir=\"TD\"\n",
    "          \n",
    "        )\n",
    "        mdf_model.to_graph_image(\n",
    "            engine=\"dot\",\n",
    "            output_format=\"png\",\n",
    "            view_on_render=False,\n",
    "            level=3,\n",
    "            filename_root=\"sample1_pytorch_to_mdf\",\n",
    "            only_warn_on_fail=True,  # Makes sure test of this doesn't fail on Windows on GitHub Actions\n",
    "          \n",
    "        )\n",
    "    # export to PyTorch graph\n",
    "    if \"-graph-torch\" in sys.argv:\n",
    "        make_dot(output, params=dict(list(model.named_parameters()))).render(\n",
    "            \"sample1_pytorch_to_mdf_torchviz\", format=\"png\"\n",
    "        )\n",
    "    # export to onnx graph\n",
    "    if \"-graph-onnx\" in sys.argv:\n",
    "        netron.start(\"sample1_pytorch_to_mdf.onnx\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QDdRPYBu6apd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
